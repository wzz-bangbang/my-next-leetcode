#### 用过的 AI 大模型，使用方式，用了他们那些功能，觉得 AI 大模型他们存在有什么样的缺点

我主要用过 **通用大模型（Chat 类）+ 编程向模型（Code 类）**，日常是“问题分析 + 代码生成 + 校验优化”结合使用。

**使用方式**

- 需求理解 / 技术方案拆解（让模型帮我把问题结构化）
- 写代码骨架 / 示例实现（我负责判断可行性）
- Debug：解释报错、分析边界 case
- 文档/注释/测试用例生成
  **常用功能**
- 多轮对话推理（不是一次性生成）
- 代码补全 / 重构建议
- 解释陌生代码或项目结构
- 对比方案（如性能、可维护性）
  **我看到的主要缺点（重点说这段）**

1. **幻觉问题**：会“自信地胡说”，尤其是 API、版本差异
2. **上下文有限**：复杂项目需要我主动裁剪、喂关键信息
3. **缺乏真实运行反馈**：生成的代码不等于可上线代码
4. **工程判断不可靠**：架构/边界/取舍仍要人来定
5. **不会推测交互上下文**：需要依赖程序员的经验

#### 你对 AI Coding 的理解？

我理解的 AI Coding 不是“替代程序员写代码”，而是**把程序员从低价值的重复劳动中解放出来**。

我把 AI Coding 分成三层能力：

1. **生成层**：
   - 写样板代码、CRUD、工具函数
2. **理解层**：
   - 拆解需求、解释代码、总结逻辑、帮助我快速上手陌生项目
3. **协作层（我更看重）**： - 和我一起查问题、分析方案、发现盲点
   但它**不擅长**：

- 复杂业务建模
- 架构取舍
- 非显性需求（性能、稳定性、灰度、回滚）
- 涉及交互上下文的场景，AI 不会联系上下文和预设用户操作逻辑

所以我把 AI 当成“非常快的初级工程师 + 技术顾问”\*\*，最终决策仍由我负责。

#### 使用 AI 工具方面，你自己有没有最佳实践？

**我总结最佳实践有三点：**

1. **先给上下文，再让它写**，可以通过配置项目 rules 来简化流程
   - 项目背景 / 技术栈 / 约束条件
   - 不直接丢一句“帮我写代码”
2. **让 AI 解释它写的代码**
   - 看它的解释，能快速发现逻辑漏洞或误解
3. 可以让 AI 先给出方案，再对他的方案进行选择和优化，再执行
4. **永远保留人工校验**
   - 类型检查
   - 代码 review
   - 单测+自测，尤其关键路径我一定自己过一遍

一句话总结：**AI 负责速度，程序员负责正确性和边界**

#### 平时的 AI 工作流 是怎样的？

一个典型流程是：

1. **我先自己分析需求点和方向，捋清楚目标和约束**
2. 复杂问题先帮我拆步骤 / 给实现思路和方案
3. **我来判断方案是否合理**
   - 是否符合现有架构
   - 是否有性能/安全问题
4. 再让 AI 生成代码，然后 review 再做针对性调整，优化细节

#### 用过哪些 AI IDE？差异在哪？

1. Cursor：目前的“全能王者”。**核心功能：**
   - **Tab (预测式补全)：** 极其强大的上下文预测，能根据你的逻辑预测下一段代码。
   - **产品化程度最高**。它将 AI 深度集成到 UI 层（如下滑提示、浮动按钮），体验远超“编辑器 + 插件”的组合。通过配置 cursor rule，结合一系列 ai 工具快捷键，**Agent 模式**能极大提升效率
2. **claude code**：运行在终端的“高级机器人”
   - \*\*运行在终端，无 UI，不限制在项目内，拥有读写文件和执行命令的完整闭环（会请求操作权限）
   - \*\*逻辑推理强，处理复杂逻辑能力强
   - 自主循环 (Loop)：读代码-分析-修改-验证，自主性比较强
3. 国内
   1. Trae：**独立的 IDE**，Agent 模式，跨文件的全局重构能力更强，基于 Claude GPT 等模型
   2. 通义灵码：国内目前生态最成熟、用户量最大的 AI 编程助手，主要以 **IDE 插件**（VS Code, JetBrains）形式存在。对中文 Prompt 的理解非常细腻，单元测试生成、研发文档编写能力好，底层通义千问大模型

#### 对 Agent / MCP / Tab 补全模型 的理解？

我把它们理解成三种不同抽象层级的 AI 能力。

1. Tab 补全模型（最低层）

   - 基于上下文预测下一段代码
   - 适合：
     - 写样板代码
     - 局部修改
   - **优点**：快、低打扰
   - **缺点**：不理解“任务目标”，尤其没有完整的任务和需求观

2. Agent（任务级）

   - 能理解“我要完成一件事”
   - 会拆步骤、调用工具、反复修正
   - ## 适合：
     - 重构
     - 批量修改
     - 跨文件操作
   - 风险：
     - **权限过大时需要强约束**，尽量结合自定义规则
     - agent 生成的代码经常过度（写很多不需要的东西），需要比较细致的 review

3. MCP（能力/工具协议层）

   - MCP 我更倾向理解为 **“让 AI 安全、可控地接入外部能力的标准接口”**。
     - 规范 AI 能调用什么
     - 能看到什么数据
     - 能做多大范围的事
   - **价值在于：**
     - 降低 Agent 的失控风险
     - 让 AI 更工程化，而不是玩具化

Tab 补全解决“写得快”，Agent 解决“做成事”，MCP 解决“做得安全、可控”。

#### 说说 mcp 的原理和底层架构

**MCP（Model Context Protocol）是一套标准化协议，用来把 LLM 与外部工具/数据源解耦连接**。  
它通过 **Host → Client → Server** 的分层架构，把“模型如何思考”和“工具如何实现”彻底分开，使模型可以在不改代码的情况下安全、可控地调用外部能力。

1. MCP 要解决的核心问题是什么？
	在 MCP 之前，LLM 调工具通常有几个痛点：
	- 工具接口**不统一**（每个工具一套 schema）
	- LLM **强绑定实现细节**（换个工具就要改 prompt / 代码）
	- **权限、安全、环境**混在一起（LLM 直接碰真实系统）
	- 工具发现、能力描述不规范（模型“猜着用”）
	**MCP 的目标**：把「能力」标准化、把「执行」隔离出去，让 LLM 只做“决策”，不做“执行”。
	
2. MCP 整体架构和角色
	1. Host（宿主）：用户交互入口（IDE、Chat App），负责：
		- 管理 MCP Server 配置
		- 启动/连接 MCP Server
		- 把 LLM 的 MCP 调用转成真实请求
	2. LLM（模型）
		- **不直接访问任何系统** 
		- 理解用户意图
		- 决定“要不要调用 MCP”
		- 生成 **符合 MCP schema 的结构化请求** 
	3. MCP Client（协议客户端），通常是 **Host 内部的一个模块**
		- 校验 MCP 请求是否合法
		- 路由到正确的 MCP Server
		- 做协议层通信（stdio / http / ws）
	4. MCP Server（能力提供方）
		- 独立进程 / 服务
		- 向外声明：
		    - 自己有哪些能力（tools / resources / prompts）
		    - 每个能力的 schema（JSON Schema）
		- 负责：
		    - 真正执行系统操作
		    - 返回结构化结果
		- **可以是任何语言实现**
	
3. MCP 的调用流程
	1. 用户提问
	2. Host 把上下文 + MCP 能力列表给 LLM
	3. LLM 判断：需要调用 MCP
	4. LLM 输出 **结构化 MCP 调用**
	5. Host 解析 → MCP Client
	6. MCP Client → MCP Server
	7. MCP Server 执行真实操作
	8. 返回结果
	9. Host 把结果再交给 LLM
	10. LLM 生成最终自然语言回复
	
4. MCP Server的内部结构（底层视角）
	1. Transport Layer（传输层）
		- 常见的 stdio（本地工具） / http / ws
	2. Protocol Layer（协议层）负责 MCP 的 **schema 的结构化协议**
		- schema核心特征：
		    - 明确的 request / response
		    - 参数、返回值都有 JSON Schema
		    - 不靠 prompt 文本约定
	3. Capability Layer（能力声明层）这是 MCP 的灵魂
		MCP Server 可以暴露三类能力：
		- tools：可执行动作（最常见），类似函数调用
		- resources：只读或半结构化数据，类似“数据源”
		- prompts：可复用 prompt 模板
	4. Adapter Layer（适配层）
		- 真正对接：
		    - 文件系统
		    - Git
		    - 数据库
		    - 内部服务
